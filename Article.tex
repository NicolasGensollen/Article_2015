%&latex
%%----------------------------------------------------------------------
%% ieeepes_skel.tex
%%
%% Skeleton file for papers for the IEEE Power Engineering Society using
%% package ieeepes.
%%
%% Not copyrighted. Copy this file to a different name and fill in your
%% text.
%%
%% Volker Kuhlmann
%% c/o EEE Dept
%% University of Canterbury
%% Private Bag 4800
%% Christchurch, New Zealand
%% Email: KUHLMAV@ELEC.CANTERBURY.AC.NZ
%%
% 1.3  13Apr99  Updated for ieeepes 4.0.
% 1.2  16Nov95  Fixed discussion, closure. Added summary.
% 1.1  12Nov95  Finished first release.
% 1.02 09Nov95  Option PStimes.
% 1.0  07Nov95  Created.
%%----------------------------------------------------------------------
 
\documentclass[10pt,twoside%
                ,draft%         % comment this out for final version
        ]{article}


\usepackage[%
        %       psphotos,%      % uncomment those options you want
        %       photofit,%
        %       draft,%
        %       PStimes,%
        ]{ieeepes}
\usepackage{algpseudocode}
\usepackage{algorithm}

\title{Control of Prosumer Networks}

\author{
        N. Gensollen\\
        Institut Mines Telecom\\
        Saclay, France
\and
        V. Gauthier\\
        Institut Mines Telecom\\
        Saclay, France
}



\begin{document}


% This \maketitle command is required from ieeepes version 4.0, to make
% ieeepes work correctly with newer LaTeX versions.
\maketitle


\begin{abstract}
Put the text of your abstract here.
\end{abstract}



\section{Introduction}

Modernizing the power grids and increasing the share of renewables in the production are two substantial objectives of the energetic transition. Because of parallel progresses in communication, data management, and storage, the upcoming emergence of a power grid "2.0", often called smart grid, appears as a cross-disciplinary challenge of the 21st century.

It is believed that these new ways of producing and managing energy, will also impact how end users consume. More precisely, the consumer   of the future is expected to be more involved in the system operation. Using dynamic signals (real time electricity prices for instance), load curves could be shaped to some extend as to agree with the production conditions of the main grid.
Furthermore, the emergence of renewable distributed energy 
 resources (DER) in the distribution networks, possibly hold by individuals,
will completely  
modify the today end user agent model.

These new agents that can both consume and produce are often called prosumers. This decentralized production is believed to lead to more resilient systems that today centralized power grid. Nonetheless, the difficulty of dealing with decentralized production is coupled with the high uncertainty of renewables. Ensure system stability in these conditions appears thus as a complex task. 

Relying on the ability of the smart grid to obtain, communicate and analyse data, several solutions could  improve the stability of such complex systems. Among these solutions, demand side management and energy storage are two of the most popular ones. In this paper, we explore the use of storage in a network of prosumers whose power distribution is susceptible to change due to various external causes. More precisely, we are interested in the "best" locations for the storage equipments such that we are able to maintain stability when small perturbations occur. Since all nodes can switch from generator to load and vice versa, the optimal location is susceptible to change with the prosumers power distribution.
Our goal is then to find the one that, on average, provide the best results.

Since charging and discharging a battery is costly, we are particularly interested in the energy necessary to control the system when perturbations occur. The notion of performance of a given set of locations for using storage would then be inversely proportional to the energy used. One problem with this definition is that it depends explicitly on the state of the system and the prosumers power distribution. Besides, as the system size increases, the number of possible location sets increases exponentially. This forbid any algorithms using complete enumeration and evaluation of the sets.
Moreover, we consider  that the electrical lines have maximum capacities, and storage equipments have both a maximum charge / discharge rate and  bounded capacities. Obviously, only solutions satisfying these constraints will be considered as feasible.



 In this paper, we model the prosumer network as a coupled oscillator network. Inspired by [], we use a second order Kuramoto model that can be seen as a simplified version of the underlying power grid dynamics (see Section II). We then use control theory in order to model the impact of the storage equipments on the network (see Section III). Using the relationships between submodular set functions
and the Gramian matrix [], we use a modified version of a greedy algorithm in order to find the smallest locations set that minimizes the average control energy while satisfying all the constraints introduced above (see section IV).
Finally, we show some results in Section V.\section{The Model}

In this section, we introduce the coupled oscillators network model used to simplify the power grid dynamic. The first part is largely inspired by [], and reproduced here for convenience of the reader.

 The objective is to achieve synchronization of the grid at the main frequency $ \Omega = 50 Hz $. Each oscillator i has a phase angle $ \delta_i $ and a frequency $ \dot{\delta}_i $. Therefore, we seek an equilibrium of the form : $ \forall i,\ \dot{\delta}_i = \Omega $. For convenience, we express the dynamic of the oscillators in terms of the deviations from the main frequency : $ \delta_i(t) = \Omega t + \theta_i(t) $. Let $ \omega_i = \dot{\theta_i} $, such that $ \dot{\delta_i} = \Omega + \omega_i $. The equilibrium, in terms of the deviations dynamics, is : $ \forall i,\ \omega_i = 0 $

The next step consists in translating the dynamics of the generators and machines into equations involving the phase angles $ \theta_i $ and the frequencies $ \omega_i$. Generators and machines are composed of a turbine that dissipates energy at a rate proportional to the square of the angular velocity ($P_{diss} = FV \sim V^2 $ ) : 

\begin{equation}
  P_{diss, i}(t) = K_{Di}(\dot{\delta_i}(t))^2 
\end{equation}

where $ K_{Di} $ is the dissipation constant of entity i.

Furthermore, it also accumulates kinetic energy at a rate : 

\begin{equation} 
P_{acc,i}(t) = \frac{1}{2}I_i\frac{d}{dt} \left( \dot{ \delta_i }(t)^2 \right)
\end{equation} 

where $ I_{i}$ is the moment of inertia of entity i. For simplicity, we consider that all entities have the same dissipation constants($K_D$) and moment of inertia (I).

The condition for the power transmission between i and j is that the two devices do not operate in phase : The phase difference between i and j is : $ \delta_j(t) - \delta_i(t) = \Omega t + \theta_j(t) - \Omega t - \theta_i(t) = \theta_j(t) - \theta_i(t) $.

The transmitted power along the line can thus be written as : 

\begin{equation}
 P_{transmitted} = - P_{ij}^{MAX} sin( \theta_j - \theta_i )
\end{equation}
  
with $ P_{ij}^{MAX} $ being the maximum capacity of the line $(i,j)$. If i is connected to more than one other entities, this equation becomes ($\mathcal{N}_i$ being the neighborhood of  i) : 

\begin{equation}
  P_{transmitted} = - \sum_{j \in \mathcal{N}_i} P_{ij}^{MAX} sin( \theta_j - \theta_i ) 
\end{equation}


Each entity i is then described by a power balance equation of the type :

\begin{equation}
 P_{S,i}  =  P_{diss,i} + P_{acc,i} + P_{transmitted,i} 
\end{equation}

By substituting and re-arranging the terms, we obtain the following non-linear coupled system of equations :

\begin{equation}
\begin{array}{lll}
P_{S, i}  =  I \Omega \ddot{ \theta_i }  + \left[ I \ddot{ \theta_i } + 2 K_D \Omega \right] \dot{ \theta_i } + K_D \Omega^2 \\+ K_D \dot{ \theta_i }^2 - \sum_{j \in \mathcal{N}_i} P_{ij}^{MAX} sin \left[ \theta_j - \theta_i \right] \end{array}
\end{equation}

These non linear equations are obviously not very practical. We now use some approximations based on the fact that we consider only small deviations from the main frequency : $ \dot{ \delta}_i \sim \Omega $ which means that $ \omega_i = \dot{\theta_i} << \Omega $, such that the squared term $ K_D \dot{\theta}_i^2 $ can be neglected.
Moreover, we assume that the rate at which energy is stored in the kinetic term is much less of the rate at which energy is dissipated by friction, a common condition for mechanical systems : $ \ddot{ \theta }_i  << \dfrac{2 K_D}{I} $

The equation can thus be simplified to :

\begin{equation}
 \ddot{ \theta_i } \sim \psi_i - \alpha \dot{ \theta_i } + \sum_{j\neq i} K_{ij} g_{ji} sin \left[ \theta_j - \theta_i \right] 
\end{equation}

Where $ \alpha = \dfrac{2 K_D}{I} $ is the dissipation term, $ K_{ij} = \frac{P_{ij}^{MAX}}{I \Omega} $ are the coupling strengths, $ \psi_i = \left[ \frac{P^i_{source}}{I \Omega} - \frac{K_D \Omega}{I} \right] $, and $ g_{ij} $ is the coefficient of the adjacency matrix G.

The dynamic is still non linear because of the sine coupling. Therefore, we also assume that the phase angle differences are small such that $ sin \left[ \theta_j - \theta_i \right] \sim \theta_j - \theta_i $. By using vector notations, the dynamic can be written in the following form :

\begin{equation}
\ddot{\theta} = \Psi - \alpha \dot{\theta} - KL\theta }
\end{equation}

Where L is the Laplacian matrix of the underlying topology ($ k_i $ is the degree of node i):

\begin{equation}
L_{ij} = \left\{ \begin{array}{lll} k_i\ \ \ \ \,if\ i=j \\ -g_{ij}\  if\ i \neq j \end{array} \right. 
\end{equation}



This is a continuous time second order linear system of $ N $ equations. We first transform this into a continuous time first order linear system of $ 2 N $ equations by introducing the following vector : $ X = \left( \begin{array}{c} \theta \\ \dot{\theta} \end{array} \right)$ : 

\begin{equation}
 \dot{X} = \left( \begin{array}{cc} 0 & I \\ - KL & -\alpha I \end{array} \right) X + \left( \begin{array}{c} 0 \\ \Psi \end{array} \right)
\end{equation}
 
Which can be written in discrete time: 

\begin{equation} 
X(t+\Delta t) = M  X(t) +  \left( \begin{array}{c} 0 \\ \Psi \Delta t \end{array} \right)
\end{equation} 

With $ M = \left( \begin{array}{cc} I & I \Delta t \\ -KL \Delta t & (1-\alpha \Delta t) I \end{array} \right) $.

By setting $ Y(t) =  \left( \begin{array}{c} X(t) \\ 1 \end{array} \right) $, let the dynamic be :

\begin{equation}
 Y(t+\Delta t) = A Y(t) }
\end{equation}

With transition matrix A :

\begin{equation}
 A =   \left( \begin{array}{ccc} I & I \Delta t & 0 \\ -KL \Delta t & (1-\alpha \Delta t)I & \Psi \Delta t \\ 0&0&1 \end{array} \right)
\end{equation}

This is a linear discrete time system of $ 2 N + 1 $ equations. Note that the transition matrix A encodes all the system parameters, topology, and power distribution.


\section{Control and Submodularity}

\subsection{Submodularity}

In this section we provide a very brief introduction to what submodular functions are, and how their maximization could be achieved in reasonable time.

 A set function $ F:2^{V} \longrightarrow \Re $ defined over a finite set V is said to be submodular if it satisfies :

\begin{equation}
\forall S,T \in V,\ F(S) + F(T) \geq F(S \cup T) + F(S \cap T)
\end{equation}

Another equivalent definition is that for all sets $ X, Y \in V$, such that $ X \subseteq Y$ and for all element $ x \in V \setminus Y$,

\begin{equation}
F(X \cup \{ x \} ) - F(X) \geq F(Y \cup \{ x \} ) - F(Y)
\end{equation} 

This basically means that submodular functions exhibit a diminishing return property which makes them particularly interesting for optimization.

Finding the set $ S_k $ of size k that maximizes a set function F is a difficult problem because the number of sets grows exponentially with the number of nodes. Therefore complete enumeration and evaluation is only a feasible solution on very small examples. Nevertheless, if the set function is submodular, a simple greedy heuristic returns a solution $ S_k^{\star} $ such that, in the worst case, $ \frac{F(S_k^{\star})}{F(S_k^{OPT})} \sim 63\%$ (where $ S_k^{OPT}$ is the optimum set of size k). 

Since the evaluation of F can be costly, a well-known lazy-greedy variation has been proposed by Minoux in 19XX. This smart implementation uses the submodular structure of the marginal gains in order to reduce drastically the number of calls to F. This can result in speedups of several order of magnitudes.

\subsection{Control}

In this section, we introduce basic tools from control theory and relate them to the submodular functions introduced above. Recall that our objective is to maintain a given state in a dynamical system even if perturbations of the power distribution occur. 

More precisely, we assume the control of a subset of the nodes that we call driver nodes. In our particular power grid situation, a driver node will be used to model a battery. This control assumption modifies the dynamic in the following way :

\begin{equation}
 Y(t+\Delta t) = A Y(t) + B u(t) 
\end{equation}

Where the control matrix B is an indicator of the driver nodes, and $ u(t) $ represents the control vector input at time t. The system is said to be controllable in T steps is it can be steered from any initial state $ Y_0 $ to any final state $ Y_f $ through a sequence of control inputs $ u(t) $. If the system is controllable, there might be more than one sequence of control inputs that could realize such a thing. Among all these possibilities, we are interested in the one that requires the minimum amount of energy. Let $ \mathcal{E} = \int_{t_0}^{t_0+T} \Vert u(t) \Vert^2 dt $ be the energy used for the control of the system.

It can be shown that the control input sequence that minimizes the control energy can be written as :

\begin{equation}
 u^{\star}(t) = B^T(A^T)^{T-t-1}W^{-1}(T)\nu(T)
\end{equation}
where $ \nu(T) = Y_f - A^T Y_0 $ is the difference between the desired final state and the final free state, and $W(T) = \sum_{k=0}^{T} A^k B B^T (A^T)^k $ is called the Gramian matrix of the system. The Gramian is a popular tool in control theory since it is deeply linked to the controllability of the system. It can indeed be shown that the system is controllable if and only if the Gramian is not singular, and that its rank indicates the dimension of the controllable subspace. Besides, the minimum control energy associated with the inputs $ u^{\star}(t)$ can be written as :

\begin{equation}
 \mathcal{E}_{min} = \nu(T)^T W^{-1}(T) \nu(T)
\end{equation}

Not surprisingly, the control energy depends on the initial and final states as well as on the inverse of the Gramian. In our prosumer case, we want to find the best battery placement, whose quality should not depend on the initial and final states. Indeed, these states as well as  the power  distribution $ \Psi $ are susceptible to change, and we would like to perform well, on average, whatever the states and distributions. Therefore, we concentrate on  the Gramian as a way to quantify the average controllability. It can indeed be verified that the Gramian does not depend on $\Psi$.

A key point to design a low consumption control is thus to understand the relationships between the control node set and the Gramian matrix. In [], the authors introduce several Gramian-based metrics that have concrete meanings in terms of the system controllability. For example, the trace of the inverse Gramian ($ Tr[ W^{-1}(T)] $) quantifies the average control energy necessary to move the system around the state space. These metrics measures some notions of the control allowed by a given driver node set. But they can be understood the other way around : what drivers should one select as to optimize a given control-based metric ? 

Using the Gramian-based metric $ \mathcal{M} $, let $ F(S) =\mathcal{M}(W_S(T))$, where $ W_S(T) $  is the Gramian matrix based on the driver node set S. [] showed that for some metrics, F is a submodular set function. This means that, for these metrics, we can use the greedy heuristic discussed above in order to maximize F.

\section{Control of the Prosumer Network}

\subsection{Controllability Constraints}

 Considering the dynamic of equation (), we notice that the Gramian based on the transition matrix A is never invertible, meaning that the system should not be controllable. It is easy to see that, indeed, we do not have full control because of the last row of the matrix. Nevertheless, as this row was only added in order to include the power distribution inside A, we do not need to control the system along this "fake" dimension. That is, we only seek the control of the system in the first $ 2N $ dimensions of the space (N phase angles $ \theta_i$ and N frequencies $\omega_i$). Therefore, whenever $ rank[ W(T) ] = 2N$, we will use the Moore-Penrose pseudo inverse of the gramian $ W^\dagger(T) $.


\subsection{Flow Constraints}

Recall that the simplified dynamic (see section II) implies that, the power transmitted on line $ (i,j)$ is $ P_{i \longrightarrow j} = -P_{ij}^{MAX} \left( \theta_j(t) - \theta_i(t) \right) $. Therefore, we write the flow constraints at time t as :

\begin{equation}
\forall (i,j) \in V^2,\ \ g_{ij} \left|\ \theta_j(t) - \theta_i(t)\ \right| \leq 1
\end{equation}
If this constraint is verified for all instant t in the control time range, then the control inputs satisfy the flow constraints. 



\subsection{Power Distribution Constraints}
As explained above, we wish to obtain results that do not depend on the power distribution $ \Psi $ of the prosumers. However, in order to achieve synchronization along with feasible power flows, we need to define some constraints on this distribution. As shown in [], a condition for achieving synchronisation in a coupled oscillators network is $ \Vert L^{\dagger}\omega \Vert_{\infty} \leq sin(\gamma) $, where L is the Laplacian matrix of the network, $ \omega $ is the vector of the natural frequencies of the oscillators, and $ \Vert x \Vert_{\infty} = max \left| x_i - x_j \right| $. If this condition is satisfied, the oscillators will synchronize at the common frequency $ \omega_{SYNC} $ with the phase lock $ g_{ij}\left| \theta_i - \theta_j \right| \leq    \gamma \in[0,\frac{\pi}{2}],\ \forall (i,j) \in V^2 $.

Therefore, we can write the following synchronization constraint :

\begin{equation}
\label{synchro_constraint}
\Vert \left( L \circ P^{MAX} \right)^{\dagger} \Psi \Vert_{\infty} \leq 1
\end{equation}

Where $ A \circ B $ represents the Hadamard product between matrices A and B. If constraint \ref{synchro_constraint} is satisfied, the oscillators will synchronize to a common frequency $ \omega_{SYNC} = \frac{\sum_{k=1}^{N}\Psi_k}{\sum_{k=1}^{N}\alpha_k} $, and the flows at steady state will be feasible. Note that $\omega_{SYNC} $ should be zero in order to synchronize to the main frequency $\Omega$ (recall that the phase angles and frequencies represent deviations from $ \Omega$). This gives the following intuitive zero sum constraint :

\begin{equation}
\label{zero_sum_constraint}
\sum_{k=1}^{N} \Psi_k = 0
\end{equation}

Constraint \ref{zero_sum_constraint} simply states that production should match demand in order for the system to remain stable.


\subsection{Battery Constraints}

Let i be a battery. In the simple model we adopt here, it is characterised by its maximum charge/discharge rate $r_i$, the amount of energy stored at time t $ \Lambda_i(t) $, and its maximum capacity $ \Lambda_{i, MAX} $. For simplicity, we will consider all maximum charge/discharge rates to be the same ($r$), and all maximum capacities to be the same $\Lambda_{Max}$. Furthermore, we denote by $ \Lambda(t) $ the vector of energy level at time t.

Since the control input vector $ u^{\star}(t) $ specifies the control inputs, the energy level dynamic of the batteries can be written as :

\begin{equation}
\Lambda(t+\Delta t) = \Lambda(t) - u^{\star}(t) I \Omega 
\end{equation}

Which can also be written as :

\begin{equation}
\Lambda(t)  = \Lambda(0) - I \Omega \sum_{k=0}^{t}u^{\star}(k)
\end{equation}

Where $ \Lambda(0) $ is the vector of initial levels in the batteries.

Obviously, the energy level in a battery is bounded. This leads to the following set of constraints : 

\begin{equation}
\label{level_constraints}
 \forall t, \ \ 0 \leq \Lambda(t) \leq \Lambda_{Max}
\end{equation}
 
Finally, during each time slot, the battery cannot charge or discharge at a rate higher than $ r $ : 

\begin{equation}
\label{rate_constraints}
 \forall t,\ \ \left|\ u^{\star}(t)I \Omega\ \right| \leq r 
 \end{equation}

If, for a given $ u^{\star} $, the constraints of eq. \ref{level_constraints} and \ref{rate_constraints} are satisfied, then the control inputs satisfy the storage constraints.

\subsection{Algorithm}

We propose the following greedy algorithm in order to find the smallest set of locations that minimizes the average control energy and satisfy the constraints. We assume here that the have a given initial state $ Y_0 $ and a desired final state $ Y_f$ that we want to reach in $ T $ time steps. The algorithm \ref{algo_1} starts with an empty set and, as long as that constraints are not satisfied, it increases the size of the set. For a given size k, the set $ S_k $ is found using lazy greedy submodular optimization of a Gramian-based set function F. In practice we use $ F(S) = -Tr \left[ W_S^{\dagger}(T) \right] $ which quantifies the average energy required to move the system around the controllable subspace. The algorithm \ref{algo_1} returns then the tuple $ (k,S_k,u^{\star}) $ such that $ S_k $ is the smallest set that minimizes the average control energy and, in this case, satisfies the constraints with control $u^{\star}$. 

\begin{algorithm}
\label{algo_1}
        \begin{algorithmic}
                \While {\small $ Not\ \left\{ \begin{array}{lll} rank \left[ W_{S_k}(T) \right] < 2N\ and \\ \forall t,\ \forall (i,j) \in V^2,\ g_{ij} \left|\theta_j(t)-\theta_i(t) \right| \leq 1\ and \\ \forall t,\ 0 \leq \Lambda(t) \leq \Lambda_{MAX}\ and \\ \forall t,\ u^{\star}(t)I\Omega \leq r\end{array} \right. $ }
    \State $k\ \ \ \ \ \ \ \ \ \ \ \gets k+1$
    \State $ S_k \ \ \ \ \ \ \ \ \ \gets Subopt(F, k)$
    \State $ u^{\star}(t)\ \ \ \ \ \ \gets OptControl(S_{k})$ 
    \State $ Y(t), \Lambda(t) \gets Simulation(A,B,T,Y_0,Y_f,u^{\star}) $

        \end{algorithmic}
\end{algorithm}
\normalsize
Since changing $ \Psi $, $Y_0$, or $Y_f$ does not change the Gramian, variations in the power distribution or initial and final states will not change the $S_k$ whatever k. However, they have an impact on the flows and battery levels since they appear explicitly in the control energy.



\section{Results}


\bibliography{FilenameOfYourBibliography}




\end{document}

%%
%% EOF ieeepes_skel.tex
%%----------------------------------------------------------------------

